{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwAfnJ/NdSMnPTG1vCyBqM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chema74/AI-Portfolio-2025/blob/main/02_Data_Wrangling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üõ†Ô∏è M√≥dulo 2: Limpieza y Preparaci√≥n de Datos (Data Wrangling)\n",
        "\n",
        "La limpieza de datos se refiere al proceso de **detectar y corregir (o eliminar)** registros corruptos o inexactos, incompletos o irrelevantes en un conjunto de datos. Se estima que esta fase consume hasta el **80% del tiempo** total de un proyecto de ML.\n",
        "\n",
        "## Conceptos Clave del Data Wrangling\n",
        "\n",
        "### 1. Manejo de Valores Faltantes (Missing Data - `NaN`)\n",
        "Los valores faltantes (representados como `NaN` en Pandas) pueden arruinar un modelo de ML. Las estrategias m√°s comunes son:\n",
        "* **Eliminaci√≥n:** Eliminar filas o columnas que contienen `NaN`. (Solo se recomienda si hay muy pocos datos faltantes).\n",
        "* **Imputaci√≥n:** Rellenar los `NaN` con un valor calculado, como la **media (mean)**, la **mediana (median)** o el **modo (mode)** de la columna.\n",
        "\n",
        "### 2. Manejo de Datos Duplicados\n",
        "Tener filas id√©nticas puede sesgar el modelo. Es fundamental identificarlas y eliminarlas.\n",
        "\n",
        "### 3. Codificaci√≥n de Variables Categ√≥ricas\n",
        "Los modelos de ML solo entienden n√∫meros. Las variables categ√≥ricas (como 'Ciudad', 'Color' o 'Tipo de Producto') deben convertirse a formato num√©rico:\n",
        "* **One-Hot Encoding:** Crea una nueva columna binaria (0 o 1) por cada categor√≠a √∫nica. Es el m√©todo m√°s com√∫n para categor√≠as sin orden.\n",
        "* **Label Encoding:** Asigna un n√∫mero entero a cada categor√≠a. √ötil para categor√≠as ordinales (ej. 'Peque√±o'=1, 'Mediano'=2, 'Grande'=3)."
      ],
      "metadata": {
        "id": "otC28UYHfZPB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora crearemos un DataFrame con problemas (valores faltantes y categor√≠as) y lo limpiaremos, siguiendo las mejores pr√°cticas de documentaci√≥n."
      ],
      "metadata": {
        "id": "1EWuChOQfiNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================================================\n",
        "# PASO 1: Importar librer√≠as\n",
        "# =======================================================\n",
        "import pandas as pd\n",
        "import numpy as np  # La librer√≠a numpy se usa para crear el valor NaN (Not a Number)\n",
        "\n",
        "print(\"‚úÖ Librer√≠as importadas para la limpieza de datos (Data Wrangling).\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# =======================================================\n",
        "# PASO 2: Crear un DataFrame de ejemplo con problemas (Datos 'Sucios')\n",
        "# =======================================================\n",
        "\n",
        "datos_sucios = {\n",
        "    'ID_Transaccion': [101, 102, 103, 104, 105, 106, 104], # La ID 104 est√° duplicada\n",
        "    'Producto': ['A', 'B', 'A', 'C', 'B', 'A', 'C'],\n",
        "    'Precio_Unitario': [15.5, np.nan, 15.5, 22.0, 10.0, np.nan, 22.0], # Valores faltantes (NaN)\n",
        "    'Cantidad': [3, 1, 3, 2, 4, 1, 2],\n",
        "    'Region': ['Norte', 'Sur', 'Norte', 'Oeste', 'Este', 'Sur', 'Oeste'] # Variable categ√≥rica a codificar\n",
        "}\n",
        "\n",
        "# Creamos el DataFrame inicial\n",
        "df_ventas = pd.DataFrame(datos_sucios)\n",
        "\n",
        "print(\"1. DataFrame Inicial (con problemas):\\n\")\n",
        "print(df_ventas)\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# =======================================================\n",
        "# PASO 3: Manejo de Datos Duplicados\n",
        "# =======================================================\n",
        "\n",
        "# 3a. Contar filas duplicadas (por defecto, revisa si toda la fila es id√©ntica)\n",
        "num_duplicados = df_ventas.duplicated().sum()\n",
        "print(f\"2. N√∫mero de filas duplicadas encontradas: {num_duplicados}\")\n",
        "\n",
        "# 3b. Eliminamos las filas duplicadas, manteniendo la primera aparici√≥n (keep='first').\n",
        "# Usamos .copy() expl√≠citamente para asegurar que 'df_limpio' sea una copia independiente\n",
        "# y evitar el 'SettingWithCopyWarning' al modificarlo despu√©s.\n",
        "df_limpio = df_ventas.drop_duplicates().copy()\n",
        "\n",
        "print(f\"3. Filas despu√©s de eliminar duplicados: {len(df_limpio)}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# =======================================================\n",
        "# PASO 4: Manejo de Valores Faltantes (Imputaci√≥n)\n",
        "# =======================================================\n",
        "\n",
        "# 4a. Calculamos el valor de imputaci√≥n. Usamos la mediana para ser robustos ante at√≠picos.\n",
        "mediana_precio = df_limpio['Precio_Unitario'].median()\n",
        "\n",
        "# 4b. Imputamos los valores NaN.\n",
        "# La mejor pr√°ctica es asignar el resultado de la funci√≥n directamente a la columna,\n",
        "# en lugar de usar el obsoleto 'inplace=True'.\n",
        "df_limpio['Precio_Unitario'] = df_limpio['Precio_Unitario'].fillna(mediana_precio)\n",
        "\n",
        "print(f\"4. Mediana del Precio usada para imputar: {mediana_precio:.2f}\")\n",
        "print(\"5. Verificamos si quedan valores NaN en 'Precio_Unitario':\")\n",
        "print(f\"   N√∫mero de NaN: {df_limpio['Precio_Unitario'].isnull().sum()}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "\n",
        "# =======================================================\n",
        "# PASO 5: Codificaci√≥n de Variables Categ√≥ricas (One-Hot Encoding)\n",
        "# =======================================================\n",
        "\n",
        "# La columna 'Region' es nominal y debe convertirse a n√∫meros binarios.\n",
        "# Usamos pd.get_dummies() para aplicar One-Hot Encoding.\n",
        "# Esto crea una columna por cada valor √∫nico en 'Region' (Norte, Sur, Oeste, Este).\n",
        "df_codificado = pd.get_dummies(df_limpio, columns=['Region'], prefix='Region')\n",
        "\n",
        "print(\"6. DataFrame Final (Limpio e Imputado, con One-Hot Encoding aplicado):\\n\")\n",
        "print(df_codificado)\n",
        "print(\"\\nNota: Se han creado nuevas columnas binarias para cada regi√≥n (Region_Este, Region_Norte, etc.).\")\n",
        "print(\"-\" * 70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrrlAMIMfk4p",
        "outputId": "40c30fdb-d88c-4e60-9210-61312bbf8306"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Librer√≠as importadas para la limpieza de datos (Data Wrangling).\n",
            "----------------------------------------------------------------------\n",
            "1. DataFrame Inicial (con problemas):\n",
            "\n",
            "   ID_Transaccion Producto  Precio_Unitario  Cantidad Region\n",
            "0             101        A             15.5         3  Norte\n",
            "1             102        B              NaN         1    Sur\n",
            "2             103        A             15.5         3  Norte\n",
            "3             104        C             22.0         2  Oeste\n",
            "4             105        B             10.0         4   Este\n",
            "5             106        A              NaN         1    Sur\n",
            "6             104        C             22.0         2  Oeste\n",
            "----------------------------------------------------------------------\n",
            "2. N√∫mero de filas duplicadas encontradas: 1\n",
            "3. Filas despu√©s de eliminar duplicados: 6\n",
            "----------------------------------------------------------------------\n",
            "4. Mediana del Precio usada para imputar: 15.50\n",
            "5. Verificamos si quedan valores NaN en 'Precio_Unitario':\n",
            "   N√∫mero de NaN: 0\n",
            "----------------------------------------------------------------------\n",
            "6. DataFrame Final (Limpio e Imputado, con One-Hot Encoding aplicado):\n",
            "\n",
            "   ID_Transaccion Producto  Precio_Unitario  Cantidad  Region_Este  \\\n",
            "0             101        A             15.5         3        False   \n",
            "1             102        B             15.5         1        False   \n",
            "2             103        A             15.5         3        False   \n",
            "3             104        C             22.0         2        False   \n",
            "4             105        B             10.0         4         True   \n",
            "5             106        A             15.5         1        False   \n",
            "\n",
            "   Region_Norte  Region_Oeste  Region_Sur  \n",
            "0          True         False       False  \n",
            "1         False         False        True  \n",
            "2          True         False       False  \n",
            "3         False          True       False  \n",
            "4         False         False       False  \n",
            "5         False         False        True  \n",
            "\n",
            "Nota: Se han creado nuevas columnas binarias para cada regi√≥n (Region_Este, Region_Norte, etc.).\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}